{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,47,123,124,125,128,129,130,133) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n"
     ]
    }
   ],
   "source": [
    "%run load_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loan grade distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution of interest rates for each loan grade\n",
    "\n",
    "for grade in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:\n",
    "    subset = frame['grade'] == grade\n",
    "    frame['int_rate_num'][subset].hist(label = grade, normed = True, alpha = 0.75)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Interest Rates by Loan Grades\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Interest Rate\")\n",
    "plt.savefig(\"interestratehistogram.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression of probability of going bad on pre-application characteristics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_features, train_labels[\"bad\"])\n",
    "test_features['pred_fail_rate'] = lr.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "linreg = linear_model.LinearRegression()\n",
    "linreg.fit(train_features, train_labels[\"bad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "linregCO = sm.OLS(train_labels[\"bad\"], sm.add_constant(train_features)).fit()\n",
    "linregCO.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linreg_ret = sm.OLS(train_labels[\"return\"], sm.add_constant(train_features)).fit()\n",
    "linreg_ret.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linreg_rec = sm.OLS(train_labels[train_labels.bad == 0][\"return\"], \n",
    "                    sm.add_constant(train_features[train_labels.bad == 0])).fit()\n",
    "linreg_rec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linreg_rec_rate = sm.OLS(train_labels[train_labels.bad == 1][\"return\"], \n",
    "                         sm.add_constant(train_features[train_labels.bad == 1])).fit()\n",
    "linreg_rec_rate.summary()\n",
    "test_features[\"pred_rec_rate\"] = linreg_rec_rate.predict(test_features.drop(\"pred_fail_rate\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       ,  0.0147042],\n",
       "       [ 0.0147042,  1.       ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(test_features[[\"pred_fail_rate\", \"pred_rec_rate\"]], rowvar=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute expected gross return R\n",
    "\n",
    "test_features[\"exp_R\"] = ((1 + test_features[\"int_rate_num\"]) * (1 - test_features[\"pred_fail_rate\"]) +\n",
    "                         test_features[\"pred_rec_rate\"] * test_features[\"pred_fail_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are cross moments predictable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features1 = train_features.iloc[:1000, :20].copy()\n",
    "labels1 = train_labels.iloc[:1000, :20].copy()\n",
    "features2 = train_features.iloc[1000:2000, :20].copy()\n",
    "labels2 = train_labels.iloc[1000:2000, :20].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/statsmodels/base/model.py:1036: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/anaconda/lib/python3.6/site-packages/statsmodels/base/model.py:1042: RuntimeWarning: invalid value encountered in absolute\n",
      "  return stats.t.sf(np.abs(self.tvalues), df_resid)*2\n",
      "/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "linreg_rec_rate2 = sm.OLS(train_labels[train_labels.bad == 1][\"return\"] ** 2, \n",
    "                         sm.add_constant(train_features[train_labels.bad == 1])).fit()\n",
    "linreg_rec_rate2.summary()\n",
    "test_features[\"pred_rec_rate2\"] = linreg_rec_rate2.predict(sm.add_constant(test_features.iloc[:,:107]))\n",
    "\n",
    "test_features[\"var_R\"] = ((1 + test_features[\"int_rate_num\"])**2 * (1 - test_features[\"pred_fail_rate\"]) +\n",
    "                         test_features[\"pred_rec_rate2\"] * test_features[\"pred_fail_rate\"] \n",
    "                         - test_features[\"exp_R\"]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linreg_rec_rate3 = sm.OLS(train_labels[train_labels.bad == 1][\"return\"] ** 3, \n",
    "                         sm.add_constant(train_features[train_labels.bad == 1])).fit()\n",
    "linreg_rec_rate3.summary()\n",
    "\n",
    "test_features[\"pred_rec_rate3\"] = linreg_rec_rate3.predict(test_features.iloc[:, :107])\n",
    "\n",
    "test_features[\"exp_R3\"] = ((1 + test_features[\"int_rate_num\"])**3 * (1 - test_features[\"pred_fail_rate\"]) +\n",
    "                           test_features[\"pred_rec_rate3\"] * test_features[\"pred_fail_rate\"])\n",
    "\n",
    "test_features.eval(\"skew_R = (exp_R3 - 3 * exp_R * var_R - exp_R ** 3)\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm.OLS(grades[\"grade_A\"], sm.add_constant(test_features[[\"var_R\", \"skew_R\"]])).fit(cov_type='HC0').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.stats.outliers_influence\n",
    "\n",
    "statsmodels.stats.outliers_influence.variance_inflation_factor(test_features[[\"var_R\", \"skew_R\"]].values, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Regressions for Each Loan Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regressions of rates on personal characteristics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_features_no_int = train_features.iloc[:, :107].drop(\"int_rate_num\", 1)\n",
    "test_features_no_int = test_features.iloc[:, :107].drop(\"int_rate_num\", 1)\n",
    "\n",
    "for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]: \n",
    "    \n",
    "    lr_fail_rate = LogisticRegression()\n",
    "    lr_fail_rate.fit(train_features_no_int[train_labels[\"grade_\" + grade] == 1], \n",
    "                     train_labels[train_labels[\"grade_\" + grade] == 1][\"bad\"])\n",
    "    test_features[\"pred_fail_rate_\" + grade] = lr_fail_rate.predict_proba(test_features_no_int)[:, 1]\n",
    "    \n",
    "    mask = (train_labels[\"grade_\" + grade] == 1) & (train_labels[\"bad\"] == 1)\n",
    "    lr_rec_rate = sm.OLS(train_labels[mask][\"return\"], sm.add_constant(train_features_no_int[mask])).fit()\n",
    "    test_features[\"pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_no_int)\n",
    "    \n",
    "    lr_rec_rate2 = sm.OLS(train_labels[mask][\"return\"] ** 2, sm.add_constant(train_features_no_int[mask])).fit()\n",
    "    test_features[\"pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_no_int)\n",
    "    \n",
    "    r = np.mean(train_features[train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "    \n",
    "    test_features[\"exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                         test_features[\"pred_rec_rate_\" + grade] * test_features[\"pred_fail_rate_\" + grade])\n",
    "    \n",
    "    test_features[\"var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                         test_features[\"pred_rec_rate2_\" + grade] * test_features[\"pred_fail_rate_\" + grade] \n",
    "                         - test_features[\"exp_R_\" + grade]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "    plt.plot(test_features[test_labels[\"grade_\" + grade] == 1][\"exp_R_\" + grade], \n",
    "             test_features[test_labels[\"grade_\" + grade] == 1][\"var_R_\" + grade], \n",
    "             marker='o', linestyle='', label=grade, alpha = 0.25)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Loans by Estimated Return and Variance\")\n",
    "plt.xlabel(\"Return\")\n",
    "plt.ylabel(\"Variance\")\n",
    "fig1 = plt.gcf()\n",
    "fig1.savefig('returnvariance.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Discrete Choice Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define negative log-likelihood function\n",
    "\n",
    "def nllh(beta, features, labels):\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        utilities[grade] = np.dot(features[[\"exp_R_\" + grade, \"var_R_\" + grade]].values, beta)\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    term1 = np.sum(utilitiesArray * indicatorArray, axis=1)\n",
    "    term2 = np.log(np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    return -1 * np.sum(term1 - term2)\n",
    "\n",
    "def grad(beta, features, labels):\n",
    "    X1, X2 = {}, {}\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        X1[grade] = features[\"exp_R_\" + grade].values\n",
    "        X2[grade] = features[\"var_R_\" + grade].values\n",
    "        utilities[grade] = np.dot(features[[\"exp_R_\" + grade, \"var_R_\" + grade]].values, beta)\n",
    "    X1Array = pd.DataFrame(X1).values\n",
    "    X2Array = pd.DataFrame(X2).values\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "        \n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    \n",
    "    d1 = (np.sum(X1Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X1Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    d2 = (np.sum(X2Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X2Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    \n",
    "    return -1 * np.array([np.sum(d1), np.sum(d2)])\n",
    "\n",
    "def nllh_restriction1(beta, features, labels):\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        utilities[grade] = features[\"var_R_\" + grade].values * beta\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    term1 = np.sum(utilitiesArray * indicatorArray, axis=1)\n",
    "    term2 = np.log(np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    return -1 * np.sum(term1 - term2)\n",
    "\n",
    "def nllh_restriction2(beta, features, labels):\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        utilities[grade] = features[\"exp_R_\" + grade].values * beta\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    term1 = np.sum(utilitiesArray * indicatorArray, axis=1)\n",
    "    term2 = np.log(np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    return -1 * np.sum(term1 - term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932219.39146733168"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nllh([0,0], test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 1322473.477544718\n",
       " hess_inv: array([[ 0.00825954, -0.00601519],\n",
       "       [-0.00601519,  0.01381828]])\n",
       "      jac: array([ -2.25960928e-09,  -3.28935007e-09])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 35\n",
       "      nit: 11\n",
       "     njev: 33\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  6.43002213, -53.826577  ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run maximum likelihood estimation\n",
    "\n",
    "import scipy.optimize\n",
    "\n",
    "scipy.optimize.minimize(nllh, [0,0], jac=grad, args=(test_features, test_labels), method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5063.53252073098"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Likelihood ratio tests\n",
    "\n",
    "llh_r = scipy.optimize.minimize(nllh_restriction1, [0], args=(test_features, test_labels), method='BFGS').fun\n",
    "-2 * (1322473.477544718 - llh_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278062.39080033684"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llh_r = scipy.optimize.minimize(nllh_restriction2, [0], args=(test_features, test_labels), method='BFGS').fun\n",
    "-2 * (1322473.477544718 - llh_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   2.20000000e+04,   7.60000000e+04, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   4.00000000e+03,   6.40000000e+04, ...,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   1.05000000e+04,   3.10000000e+04, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   3.50000000e+04,   1.46000000e+05, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   5.00000000e+03,   2.63900000e+04, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def predict_MLP(train_features, train_labels, test_features):\n",
    "    train_features_no_int = train_features.iloc[:, :107].drop(\"int_rate_num\", 1)\n",
    "    test_features_no_int = test_features.iloc[:, :107].drop(\"int_rate_num\", 1)\n",
    "\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]: \n",
    "\n",
    "        mlp_fail_rate = MLPRegressor()\n",
    "        mlp_fail_rate.fit(train_features_no_int[train_labels[\"grade_\" + grade] == 1], \n",
    "                          train_labels[train_labels[\"grade_\" + grade] == 1][\"bad\"])\n",
    "        test_features[\"MLP_pred_fail_rate_\" + grade] = mlp_fail_rate.predict(test_features_no_int)\n",
    "\n",
    "#         mask = (train_labels[\"grade_\" + grade] == 1) & (train_labels[\"bad\"] == 1)\n",
    "#         lr_rec_rate = sm.OLS(train_labels[mask][\"return\"], sm.add_constant(train_features_no_int[mask])).fit()\n",
    "#         test_features[\"pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_no_int)\n",
    "\n",
    "#         lr_rec_rate2 = sm.OLS(train_labels[mask][\"return\"] ** 2, sm.add_constant(train_features_no_int[mask])).fit()\n",
    "#         test_features[\"pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_no_int)\n",
    "\n",
    "#         r = np.mean(train_features[train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "\n",
    "#         test_features[\"exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "#                              test_features[\"pred_rec_rate_\" + grade] * test_features[\"pred_fail_rate_\" + grade])\n",
    "\n",
    "#         test_features[\"var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "#                              test_features[\"pred_rec_rate2_\" + grade] * test_features[\"pred_fail_rate_\" + grade] \n",
    "#                              - test_features[\"exp_R_\" + grade]**2)\n",
    "    return\n",
    "\n",
    "PolynomialFeatures().fit_transform(train_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bootstrapping standard errors\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "iterations = 5\n",
    "size = int(len())\n",
    "\n",
    "\n",
    "\n",
    "for i in range(iterations):\n",
    "    # sample data\n",
    "    #boostrapping the training data\n",
    "    \n",
    "    bs_train_features = resample(train_features, n_samples = len(train_features))\n",
    "    bs_train_labels = resample(train_labels, n_samples = len(train_labels))\n",
    "    \n",
    "    #bs_test_features = resample(test_features, n_samples = len(test_features))\n",
    "    #bs_test_labels = resample(test_labels, n_samples = len(test_features))\n",
    "    \n",
    "\n",
    "    #creating predicted fail rate\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(bs_train_features, bs_train_labels[\"bad\"])\n",
    "    test_features['pred_fail_rate'] = lr.predict_proba(bs_test_features)[:, 1]\n",
    "    \n",
    "    \n",
    "    #predicted recovery rate and expected return and variance\n",
    "    linreg_rec_rate = sm.OLS(bs_train_labels[bs_train_labels.bad == 1][\"return\"], \n",
    "                         sm.add_constant(bs_train_features[bs_train_labels.bad == 1])).fit()\n",
    "    linreg_rec_rate.summary()\n",
    "    test_features[\"pred_rec_rate\"] = linreg_rec_rate.predict(test_features.drop(\"pred_fail_rate\", 1))\n",
    "    \n",
    "    test_features[\"exp_R\"] = ((1 + test_features[\"int_rate_num\"]) * (1 - test_features[\"pred_fail_rate\"]) +\n",
    "                         test_features[\"pred_rec_rate\"] * test_features[\"pred_fail_rate\"])\n",
    "    \n",
    "    linreg_rec_rate2 = sm.OLS(bs_train_labels[bs_train_labels.bad == 1][\"return\"] ** 2, \n",
    "                         sm.add_constant(bs_train_features[bs_train_labels.bad == 1])).fit()\n",
    "    linreg_rec_rate2.summary()\n",
    "    test_features[\"pred_rec_rate2\"] = linreg_rec_rate2.predict(sm.add_constant(test_features.iloc[:,:107]))\n",
    "\n",
    "    test_features[\"var_R\"] = ((1 + test_features[\"int_rate_num\"])**2 * (1 - test_features[\"pred_fail_rate\"]) +\n",
    "                         test_features[\"pred_rec_rate2\"] * test_features[\"pred_fail_rate\"] \n",
    "                         - test_features[\"exp_R\"]**2)\n",
    "    \n",
    "    \n",
    "    #expected return and variance by grade\n",
    "    bs_train_features_no_int = bs_train_features.iloc[:, :107].drop(\"int_rate_num\", 1)\n",
    "    test_features_no_int = test_features.iloc[:, :107].drop(\"int_rate_num\", 1)\n",
    "\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]: \n",
    "    \n",
    "        lr_fail_rate = LogisticRegression()\n",
    "        lr_fail_rate.fit(bs_train_features_no_int[bs_train_labels[\"grade_\" + grade] == 1], \n",
    "                     bs_train_labels[bs_train_labels[\"grade_\" + grade] == 1][\"bad\"])\n",
    "        test_features[\"pred_fail_rate_\" + grade] = lr_fail_rate.predict_proba(test_features_no_int)[:, 1]\n",
    "    \n",
    "        mask = (bs_train_labels[\"grade_\" + grade] == 1) & (bs_train_labels[\"bad\"] == 1)\n",
    "        lr_rec_rate = sm.OLS(bs_train_labels[mask][\"return\"], sm.add_constant(bs_train_features_no_int[mask])).fit()\n",
    "        test_features[\"pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_no_int)\n",
    "    \n",
    "        lr_rec_rate2 = sm.OLS(bs_train_labels[mask][\"return\"] ** 2, sm.add_constant(bs_train_features_no_int[mask])).fit()\n",
    "        test_features[\"pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_no_int)\n",
    "    \n",
    "        r = np.mean(bs_train_features[bs_train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "    \n",
    "        test_features[\"exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                         test_features[\"pred_rec_rate_\" + grade] * test_features[\"pred_fail_rate_\" + grade])\n",
    "    \n",
    "        test_features[\"var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                        test_features[\"pred_rec_rate2_\" + grade] * test_features[\"pred_fail_rate_\" + grade] \n",
    "                         - test_features[\"exp_R_\" + grade]**2)\n",
    "    \n",
    "    #bootstrapping test_data\n",
    "    bs_test_features = resample(test_features, n_samples = len(test_features))\n",
    "    bs_test_labels = resample(test_labels, n_samples = len(test_labels))\n",
    "    \n",
    "    \n",
    "    results = scipy.optimize.minimize(nllh, [0,0,0], args=(bs_test_features, bs_test_labels), method='Nelder-Mead')['x']\n",
    "    # getting betas\n",
    "    b1.append(results[0])\n",
    "    b2.append(results[1])\n",
    "    b3.append(results[2])\n",
    "\n",
    "#standard errors\n",
    "se_b1 = np.std(b1)\n",
    "se_b2 = np.std(b2)\n",
    "se_b3 = np.std(b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
