{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,47,123,124,125,128,129,130,133) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n"
     ]
    }
   ],
   "source": [
    "%run load_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Regressions for Each Loan Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressions of rates on personal characteristics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_features_no_int = train_features.drop(\"int_rate_num\", 1)\n",
    "test_features_no_int = test_features.drop(\"int_rate_num\", 1)\n",
    "\n",
    "for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]: \n",
    "    \n",
    "    lr_fail_rate = LogisticRegression()\n",
    "    lr_fail_rate.fit(train_features_no_int[train_labels[\"grade_\" + grade] == 1], \n",
    "                     train_labels[train_labels[\"grade_\" + grade] == 1][\"bad\"])\n",
    "    test_features[\"pred_fail_rate_\" + grade] = lr_fail_rate.predict_proba(test_features_no_int)[:, 1]\n",
    "    \n",
    "    mask = (train_labels[\"grade_\" + grade] == 1) & (train_labels[\"bad\"] == 1)\n",
    "    lr_rec_rate = sm.OLS(train_labels[mask][\"return\"], sm.add_constant(train_features_no_int[mask])).fit()\n",
    "    test_features[\"pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_no_int)\n",
    "    \n",
    "    lr_rec_rate2 = sm.OLS(train_labels[mask][\"return\"] ** 2, sm.add_constant(train_features_no_int[mask])).fit()\n",
    "    test_features[\"pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_no_int)\n",
    "    \n",
    "    r = np.mean(train_features[train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "    \n",
    "    test_features[\"exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                         test_features[\"pred_rec_rate_\" + grade] * test_features[\"pred_fail_rate_\" + grade])\n",
    "    \n",
    "    test_features[\"var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                         test_features[\"pred_rec_rate2_\" + grade] * test_features[\"pred_fail_rate_\" + grade] \n",
    "                         - test_features[\"exp_R_\" + grade]**2)\n",
    "    \n",
    "    test_features[\"var_R_\" + grade + \"_H\"] = test_features[\"var_R_\" + grade] * (test_features[\"var_R_\" + grade] >= 0.02)\n",
    "    test_features[\"var_R_\" + grade + \"_L\"] = test_features[\"var_R_\" + grade] * (test_features[\"var_R_\" + grade] < 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022811416681872254"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(test_features[[\"var_R_\" + g for g in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Discrete Choice Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nllh(beta, features, labels):\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        utilities[grade] = np.dot(features[[\"exp_R_\" + grade, \"var_R_\" + grade]].values, beta)\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    term1 = np.sum(utilitiesArray * indicatorArray, axis=1)\n",
    "    term2 = np.log(np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    return -1 * np.sum(term1 - term2)\n",
    "\n",
    "def grad(beta, features, labels):\n",
    "    X1, X2 = {}, {}\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        X1[grade] = features[\"exp_R_\" + grade].values\n",
    "        X2[grade] = features[\"var_R_\" + grade].values\n",
    "        utilities[grade] = np.dot(features[[\"exp_R_\" + grade, \"var_R_\" + grade]].values, beta)\n",
    "    X1Array = pd.DataFrame(X1).values\n",
    "    X2Array = pd.DataFrame(X2).values\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "        \n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    \n",
    "    d1 = (np.sum(X1Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X1Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    d2 = (np.sum(X2Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X2Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    \n",
    "    return -1 * np.array([np.sum(d1), np.sum(d2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nllh2(beta, features, labels):\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        utilities[grade] = np.dot(features[[\"exp_R_\" + grade, \"var_R_\" + grade + \"_H\", \"var_R_\" + grade + \"_L\"]].values, beta)\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    term1 = np.sum(utilitiesArray * indicatorArray, axis=1)\n",
    "    term2 = np.log(np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    return -1 * np.sum(term1 - term2)\n",
    "\n",
    "def grad2(beta, features, labels):\n",
    "    X1, X2, X3 = {}, {}, {}\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        exp_R = features[\"exp_R_\" + grade]\n",
    "        var_R_H = (features[\"var_R_\" + grade]) * (features[\"var_R_\" + grade] >= 0.02)\n",
    "        var_R_L = (features[\"var_R_\" + grade]) * (features[\"var_R_\" + grade] < 0.02)\n",
    "        X = np.array([exp_R, var_R_H, var_R_L])\n",
    "        X1[grade] = exp_R.values\n",
    "        X2[grade] = var_R_H.values\n",
    "        X3[grade] = var_R_L.values\n",
    "        utilities[grade] = np.dot(X.T, beta)\n",
    "    X1Array = pd.DataFrame(X1).values\n",
    "    X2Array = pd.DataFrame(X2).values\n",
    "    X3Array = pd.DataFrame(X3).values\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    \n",
    "    d1 = (np.sum(X1Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X1Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    d2 = (np.sum(X2Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X2Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    d3 = (np.sum(X3Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X3Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    \n",
    "    return -1 * np.array([np.sum(d1), np.sum(d2), np.sum(d3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 817935.85271074797\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 0.       , -0.0349246,  0.0349246])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 60\n",
       "      nit: 12\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ -2.62191501, -41.14262413,   0.14759032])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "scipy.optimize.minimize(nllh2, [0,0,0], args=(test_features, test_labels), method='L-BFGS-B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_combined = pd.concat([train_features, train_labels], axis=1)\n",
    "test_combined = pd.concat([test_features, test_labels], axis=1)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "import scipy.optimize\n",
    "\n",
    "def bootstrap(train_combined, test_combined, iterations, results):\n",
    "    for i in range(iterations):\n",
    "        bs_train_combined = resample(train_combined)\n",
    "        bs_train_features = bs_train_combined.iloc[:, :train_features.shape[1]]\n",
    "        bs_train_labels = bs_train_combined.iloc[:, train_features.shape[1]:]\n",
    "\n",
    "        bs_test_combined = resample(test_combined)\n",
    "        bs_test_features = bs_test_combined.iloc[:, :test_features.shape[1]]\n",
    "        bs_test_labels = bs_test_combined.iloc[:, test_features.shape[1]:]\n",
    "\n",
    "        predict(bs_train_features, bs_train_labels, bs_test_features)\n",
    "\n",
    "        opt = scipy.optimize.minimize(nllh2, [0,0,0], args=(bs_test_features, bs_test_labels), \n",
    "                                      method='L-BFGS-B')\n",
    "        results.append(opt.x)\n",
    "        \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def predict(train_features, train_labels, test_features):\n",
    "    train_features_no_int = train_features.drop(\"int_rate_num\", 1)\n",
    "    test_features_no_int = test_features.drop(\"int_rate_num\", 1)\n",
    "\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]: \n",
    "\n",
    "        lr_fail_rate = LogisticRegression()\n",
    "        lr_fail_rate.fit(train_features_no_int[train_labels[\"grade_\" + grade] == 1], \n",
    "                         train_labels[train_labels[\"grade_\" + grade] == 1][\"bad\"])\n",
    "        test_features[\"pred_fail_rate_\" + grade] = lr_fail_rate.predict_proba(test_features_no_int)[:, 1]\n",
    "\n",
    "        mask = (train_labels[\"grade_\" + grade] == 1) & (train_labels[\"bad\"] == 1)\n",
    "        lr_rec_rate = sm.OLS(train_labels[mask][\"return\"], sm.add_constant(train_features_no_int[mask])).fit()\n",
    "        test_features[\"pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_no_int)\n",
    "\n",
    "        lr_rec_rate2 = sm.OLS(train_labels[mask][\"return\"] ** 2, sm.add_constant(train_features_no_int[mask])).fit()\n",
    "        test_features[\"pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_no_int)\n",
    "\n",
    "        r = np.mean(train_features[train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "\n",
    "        test_features[\"exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"pred_rec_rate_\" + grade] * test_features[\"pred_fail_rate_\" + grade])\n",
    "\n",
    "        test_features[\"var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"pred_rec_rate2_\" + grade] * test_features[\"pred_fail_rate_\" + grade] \n",
    "                             - test_features[\"exp_R_\" + grade]**2)\n",
    "        \n",
    "        test_features[\"var_R_\" + grade + \"_H\"] = test_features[\"var_R_\" + grade] * (test_features[\"var_R_\" + grade] >= 0.02)\n",
    "        test_features[\"var_R_\" + grade + \"_L\"] = test_features[\"var_R_\" + grade] * (test_features[\"var_R_\" + grade] < 0.02)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "iterations = 6\n",
    "# results = []\n",
    "\n",
    "bootstrap(train_combined, test_combined, iterations, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ -3.82909317, -40.31327598,   2.25964463]),\n",
       " array([ -4.84750167, -39.20883761,   3.79547456]),\n",
       " array([ -2.88291253, -41.17606688,  -0.71716199]),\n",
       " array([ -1.22658292, -42.62568441,  -3.46545261]),\n",
       " array([ -4.32221539, -39.82696137,   2.26231886]),\n",
       " array([ -7.00150648, -37.45627132,   9.46850808]),\n",
       " array([ -3.69381885, -39.97997708,   3.30526353]),\n",
       " array([  0.82687811, -42.50608532,  -3.21644409]),\n",
       " array([ -4.25800463, -39.86547566,   3.7137405 ]),\n",
       " array([ -3.51852037, -40.42214923,   2.50883993])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
