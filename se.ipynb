{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,47,123,124,125,128,129,130,133) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py:728: DtypeWarning: Columns (0,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exit_ignore=exit_ignore)\n"
     ]
    }
   ],
   "source": [
    "%run load_data.py;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to form predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def predict(train_features, train_labels, test_features):\n",
    "    train_features_no_int = train_features.drop(\"int_rate_num\", 1)\n",
    "    test_features_no_int = test_features.drop(\"int_rate_num\", 1)\n",
    "\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]: \n",
    "\n",
    "        lr_fail_rate = LogisticRegression()\n",
    "        lr_fail_rate.fit(train_features_no_int[train_labels[\"grade_\" + grade] == 1], \n",
    "                         train_labels[train_labels[\"grade_\" + grade] == 1][\"bad\"])\n",
    "        test_features[\"pred_fail_rate_\" + grade] = lr_fail_rate.predict_proba(test_features_no_int)[:, 1]\n",
    "\n",
    "        mask = (train_labels[\"grade_\" + grade] == 1) & (train_labels[\"bad\"] == 1)\n",
    "        lr_rec_rate = sm.OLS(train_labels[mask][\"return\"], sm.add_constant(train_features_no_int[mask])).fit()\n",
    "        test_features[\"pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_no_int)\n",
    "\n",
    "        lr_rec_rate2 = sm.OLS(train_labels[mask][\"return\"] ** 2, sm.add_constant(train_features_no_int[mask])).fit()\n",
    "        test_features[\"pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_no_int)\n",
    "\n",
    "        r = np.mean(train_features[train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "\n",
    "        test_features[\"exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"pred_rec_rate_\" + grade] * test_features[\"pred_fail_rate_\" + grade])\n",
    "\n",
    "        test_features[\"var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"pred_rec_rate2_\" + grade] * test_features[\"pred_fail_rate_\" + grade] \n",
    "                             - test_features[\"exp_R_\" + grade]**2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined training and test data sets, from which to boostrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined = pd.concat([train_features, train_labels], axis=1)\n",
    "test_combined = pd.concat([test_features, test_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import random\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nllh2(beta, features, labels, prefix = \"\"):\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        utilities[grade] = np.dot(features[[prefix + \"exp_R_\" + grade, prefix + \"var_R_\" + grade]].values, beta)\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    term1 = np.sum(utilitiesArray * indicatorArray, axis=1)\n",
    "    term2 = np.log(np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    return -1 * np.sum(term1 - term2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad(beta, features, labels, prefix = \"\"):\n",
    "    X1, X2 = {}, {}\n",
    "    utilities = {}\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "        X1[grade] = features[prefix + \"exp_R_\" + grade].values\n",
    "        X2[grade] = features[prefix + \"var_R_\" + grade].values\n",
    "        utilities[grade] = np.dot(features[[prefix + \"exp_R_\" + grade, prefix + \"var_R_\" + grade]].values, beta)\n",
    "    X1Array = pd.DataFrame(X1).values\n",
    "    X2Array = pd.DataFrame(X2).values\n",
    "    utilitiesArray = pd.DataFrame(utilities).values\n",
    "        \n",
    "    indicatorArray = labels[[\"grade_\" + x for x in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]]].values\n",
    "    \n",
    "    d1 = (np.sum(X1Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X1Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    d2 = (np.sum(X2Array * indicatorArray, axis=1) - \n",
    "     np.sum(np.exp(utilitiesArray) * X2Array, axis=1) / np.sum(np.exp(utilitiesArray), axis=1))\n",
    "    \n",
    "    return -1 * np.array([np.sum(d1), np.sum(d2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "iterations = 5\n",
    "# results2 = []\n",
    "\n",
    "def bootstrap(train_combined, test_combined, iterations, results, prefix):\n",
    "    for i in range(iterations):\n",
    "        bs_train_combined = resample(train_combined)\n",
    "        bs_train_features = bs_train_combined.iloc[:, :train_features.shape[1]]\n",
    "        bs_train_labels = bs_train_combined.iloc[:, train_features.shape[1]:]\n",
    "\n",
    "        bs_test_combined = resample(test_combined)\n",
    "        bs_test_features = bs_test_combined.iloc[:, :test_features.shape[1]]\n",
    "        bs_test_labels = bs_test_combined.iloc[:, test_features.shape[1]:]\n",
    "\n",
    "        predict(bs_train_features, bs_train_labels, bs_test_features)\n",
    "\n",
    "        opt = scipy.optimize.minimize(nllh2, [0,0], args=(bs_test_features, bs_test_labels, prefix), \n",
    "                                      jac=grad, method='BFGS')\n",
    "        results.append(opt.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bootstrap(train_combined, test_combined, 5, results2, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.DataFrame(np.array(results2))\n",
    "betas.columns = [\"beta1\", \"beta2\"]\n",
    "betas.to_csv(\"bootstrappedbetas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   24.94757402,    53.65054151,    23.03794907,    17.25683372,\n",
       "          68.6932877 ,    16.06976035,    45.69746797,    20.40846315,\n",
       "          20.04089979,    29.9786074 ,    43.88045641,    38.80576265,\n",
       "         165.04317352,    17.09162209,    16.783799  ,    27.84781858,\n",
       "          43.11656201,    30.56832731,  1917.1179319 ,    41.2470873 ,\n",
       "          31.91297107,    67.71215224,    31.27344621,    50.05307971,\n",
       "          58.31560459,    57.41590315,   -25.01919955,    30.32781618,\n",
       "          20.6626758 ,    23.03221058,    16.40633247,    28.78276697,\n",
       "          79.95712176,    15.58846259,    57.18956299,    35.30525912,\n",
       "          50.66767418,    33.96864983,    14.05759944,    29.63907932,\n",
       "        -200.74061115,    36.51362602,    33.26148764,    25.72922418,\n",
       "          25.63076605,    38.46782211,    34.20419986,    25.49703629,\n",
       "          18.3457071 ,   269.46710859,   111.48001306,    46.15033908,\n",
       "          24.66378443,    16.44358328,    -7.32044742,    17.55783891,\n",
       "          31.95911855,    76.29238431,    18.64568904,    35.01683674,\n",
       "          25.51344172,    22.01895486,    22.7620103 ,   244.08832934,\n",
       "         131.30253512,    17.3952606 ,    20.13147139,    37.89303278,\n",
       "        -211.07275048,   151.65569704,    36.47371578,    25.19345626,\n",
       "          23.06361405,    39.87217024,    45.55398424,    32.98482   ,\n",
       "          18.83206552,    35.24696963,    32.67116043,    22.52193342,\n",
       "          19.02688555,    23.47123102,    45.5153052 ,    71.56130393,\n",
       "          93.60768341,    25.22337557,    26.86191125,    30.33906121,\n",
       "          29.1038214 ,  5707.10277796,    25.23112527,    45.96366343,\n",
       "          38.4380767 ,    31.97134225,    21.27241617,    18.10559932,\n",
       "          20.79488219,    25.45136804,  -761.34983539,    27.26258357])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2 * (np.array(results2)[:,1] / np.array(results2)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.02837239,  4.33370383])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.array(results2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "train_features_poly2 = PolynomialFeatures().fit_transform(train_features.drop('int_rate_num'))\n",
    "test_features_poly2 = PolynomialFeatures().fit_transform(test_features.drop('int_rate_num'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def predict_poly2(train_features, train_features_poly2, train_labels, test_features, test_features_poly2):\n",
    "    for grade in [\"A\"]: \n",
    "\n",
    "        lr_fail_rate = sm.OLS(train_labels[train_labels[\"grade_\" + grade] == 1][\"bad\"],\n",
    "                            train_features_poly2[train_labels[\"grade_\" + grade] == 1]).fit()\n",
    "        test_features[\"poly2_pred_fail_rate_\" + grade] = lr_fail_rate.predict(test_features_poly2)\n",
    "\n",
    "        mask = (train_labels[\"grade_\" + grade] == 1) & (train_labels[\"bad\"] == 1)\n",
    "        lr_rec_rate = sm.OLS(train_labels[mask][\"return\"], train_features_poly2[mask]).fit()\n",
    "        test_features[\"poly2_pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_poly2)\n",
    "\n",
    "        lr_rec_rate2 = sm.OLS(train_labels[mask][\"return\"] ** 2, sm.add_constant(train_features_no_int[mask])).fit()\n",
    "        test_features[\"poly2_pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_poly2)\n",
    "\n",
    "        r = np.mean(train_features[train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "\n",
    "        test_features[\"poly2_exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"poly2_pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"poly2_pred_rec_rate_\" + grade] * test_features[\"poly2_pred_fail_rate_\" + grade])\n",
    "\n",
    "        test_features[\"poly2_var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"poly2_pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"poly2_pred_rec_rate2_\" + grade] * test_features[\"poly2_pred_fail_rate_\" + grade] \n",
    "                             - test_features[\"poly2_exp_R_\" + grade]**2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_poly2(train_features, train_features_poly2, train_labels, test_features, test_features_poly2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def predict_RF(train_features, train_labels, test_features):\n",
    "    train_features_no_int = train_features.drop(\"int_rate_num\", 1)\n",
    "    test_features_no_int = test_features.drop(\"int_rate_num\", 1).iloc[:, :110]\n",
    "\n",
    "    for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]: \n",
    "\n",
    "        lr_fail_rate = RandomForestRegressor(n_estimators=20)\n",
    "        lr_fail_rate.fit(train_features_no_int[train_labels[\"grade_\" + grade] == 1], \n",
    "                         train_labels[train_labels[\"grade_\" + grade] == 1][\"bad\"])\n",
    "        test_features[\"RF_pred_fail_rate_\" + grade] = lr_fail_rate.predict(test_features_no_int)\n",
    "\n",
    "        mask = (train_labels[\"grade_\" + grade] == 1) & (train_labels[\"bad\"] == 1)\n",
    "        lr_rec_rate = RandomForestRegressor(n_estimators=20)\n",
    "        lr_rec_rate.fit(sm.add_constant(train_features_no_int[mask]),\n",
    "                        train_labels[mask][\"return\"])\n",
    "        test_features[\"RF_pred_rec_rate_\" + grade] = lr_rec_rate.predict(test_features_no_int)\n",
    "\n",
    "        lr_rec_rate2 = RandomForestRegressor(n_estimators=20)\n",
    "        lr_rec_rate2.fit(sm.add_constant(train_features_no_int[mask]),\n",
    "                         train_labels[mask][\"return\"] ** 2)\n",
    "        test_features[\"RF_pred_rec_rate2_\" + grade] = lr_rec_rate2.predict(test_features_no_int)\n",
    "\n",
    "        r = np.mean(train_features[train_labels[\"grade_\" + grade] == 1][\"int_rate_num\"])\n",
    "\n",
    "        test_features[\"RF_exp_R_\" + grade] = ((1 + r) * (1 - test_features[\"RF_pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"RF_pred_rec_rate_\" + grade] * test_features[\"RF_pred_fail_rate_\" + grade])\n",
    "\n",
    "        test_features[\"RF_var_R_\" + grade] = ((1 + r)**2 * (1 - test_features[\"RF_pred_fail_rate_\" + grade]) +\n",
    "                             test_features[\"RF_pred_rec_rate2_\" + grade] * test_features[\"RF_pred_fail_rate_\" + grade] \n",
    "                             - test_features[\"RF_exp_R_\" + grade]**2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_RF(train_features, train_labels, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = scipy.optimize.minimize(nllh2, [0,0], args=(test_features, test_labels, \"RF_\"), \n",
    "                                      jac=grad, method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 865228.5081966761\n",
       " hess_inv: array([[ 0.00772618, -0.00076246],\n",
       "       [-0.00076246,  0.00722587]])\n",
       "      jac: array([ -1.00413318e-06,  -6.14838977e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 14\n",
       "      nit: 10\n",
       "     njev: 14\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-10.97814272, -25.37606111])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
